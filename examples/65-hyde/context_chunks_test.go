package main

import (
	"fmt"
	"log"
	"os"
	"strconv"
	"testing"

	"github.com/mitjafelicijan/parakeet/content"
	"github.com/mitjafelicijan/parakeet/embeddings"
	"github.com/mitjafelicijan/parakeet/enums/option"
	"github.com/mitjafelicijan/parakeet/llm"
)

// Contextual retrieval

func TestGenerateChunksWithContext(t *testing.T) {

	ollamaUrl := os.Getenv("OLLAMA_URL")
	if ollamaUrl == "" {
		ollamaUrl = "http://localhost:11434"
	}
	embeddingsModel := "mxbai-embed-large:latest"
	contextualModel := "phi3.5"
	/*
		options := llm.SetOptions(map[string]interface{}{
			option.Temperature: 0.0,
		})
	*/
	// better chunk embedding
	options := llm.SetOptions(map[string]interface{}{
		option.Temperature: 0.8,
	})

	// Initialize the vector store
	vectorStore := embeddings.DaphniaVectoreStore{}
	vectorStore.Initialize("with-context.gob")

	content.ForEachFile("./docs", ".md", func(documentPath string) error {
		fmt.Println("üìù Creating embedding from document ", documentPath)

		// Read the content of the file
		wholeDocumentContent, err := content.ReadTextFile(documentPath)
		if err != nil {
			log.Fatalln("üò°:", err)
		}

		chunks := content.ParseMarkdownWithLineage(wholeDocumentContent)

		//chunks := content.ParseMarkdownWithHierarchy(wholeDocumentContent)

		fmt.Println("üëã Found", len(chunks), "chunks")

		// Create embeddings from documents and save them in the store
		for idx, doc := range chunks {

			context, err := content.CreateChunkContext(wholeDocumentContent, doc, ollamaUrl, contextualModel, options)
			if err != nil {
				log.Println("üò°:", err)
			}
			fmt.Println("---[Chunk context]--------------------------------")
			fmt.Println(context)
			fmt.Println("--------------------------------------------------")

			fmt.Println("üìù Creating embedding from document ", idx)
			/*
				fmt.Println("Level:", doc.Level)
				fmt.Println("Prefix:", doc.Prefix)
				fmt.Println("ParentPrefix:", doc.ParentPrefix)
				fmt.Println("ParentHeader:", doc.ParentHeader)
			*/
			fmt.Println("üñºÔ∏è", doc.Header)
			fmt.Println("Lineage:", doc.Lineage)

			embedding, err := embeddings.CreateEmbedding(
				ollamaUrl,
				llm.Query4Embedding{
					Model: embeddingsModel,
					Prompt: fmt.Sprintf(
						"METADATA: %s\n\n CONTEXT: %s\n\n ## %s\n\n%s\n\n",
						doc.Lineage,
						context,
						doc.Header,
						doc.Content,
					),
				},
				documentPath+"-"+strconv.Itoa(idx),
			)
			if err != nil {
				fmt.Println("üò°:", err)
			} else {

				_, err := vectorStore.Save(llm.VectorRecord{
					Prompt:    embedding.Prompt,
					Embedding: embedding.Embedding,
					Id:        embedding.Id,
				})

				if err != nil {
					fmt.Println("üò°:", err)
				}

			}

			fmt.Println("---[Improved chunk]--------------------------------")
			fmt.Println(embedding.Prompt)
			fmt.Println("---------------------------------------------------")

		}

		return nil
	})

}
